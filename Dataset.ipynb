{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Bibliotecas necessárias"],"metadata":{"id":"pWuCbecR1pjp"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"XtRYSqPz1Eqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install PyMuPDF\n","!pip install plac\n","\n","!pip install unidecode\n","from unidecode import unidecode\n","\n","import fitz  # Módulo PyMuPDF\n","import json\n","import os\n","import re\n","from itertools import chain\n","import sys\n","import spacy\n","from __future__ import unicode_literals, print_function\n","import plac\n","import random\n","from pathlib import Path\n","from tqdm import tqdm\n","import pandas as pd\n","\n","import csv\n","csv.field_size_limit(sys.maxsize)\n","\n","!python -m spacy download pt_core_news_sm\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.stem import *\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords"],"metadata":{"id":"ZhNztM5l1KTT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sys.path.append(\"/content/drive/Shareddrives/IA 2023 - Projeto 1 Grupo 3/Scripts\")\n","import analise_edit"],"metadata":{"id":"a-jGEOwr1ZUF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Funções necessárias"],"metadata":{"id":"AlCIpRoX1xUZ"}},{"cell_type":"code","source":["NLP = spacy.load(\"pt_core_news_sm\", disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"])\n","NLP.enable_pipe(\"senter\")\n","\n","# Ajusta a formatação dos textos\n","def remove_formatting(text):\n","    text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n","    while text.find(\"  \") != -1:\n","        text = text.replace(\"  \", \" \")\n","    return text\n","\n","# Lista todos os arquivos de um diretório dado que ele seja de um formato\n","def listdir_drive(dir_path: str, formats=['pdf']) -> list:\n","    file_paths = []\n","    for root, directories, files in os.walk(dir_path):\n","        file_paths += [os.path.join(root, file) for file in files]\n","        if len(formats) > 0:\n","            file_paths = list(filter(lambda f: any([f.endswith(f\".{format}\") for format in formats]), file_paths))\n","    return file_paths\n","\n","# Extrai o texto de um PDF\n","def extract_text(pdf_path: str) -> str:\n","    doc = fitz.open(pdf_path)\n","    text = remove_formatting(\" \".join([doc[n].get_text() for n in range(doc.page_count)]))\n","    doc.close()\n","    return text\n","\n","# Retorna as publicações de um PDF\n","def get_publications(text: str):\n","    pub_texts = re.split(r'Código Identificador:\\w+', text)[1:]\n","    publications = [pub_text.strip() for pub_text in pub_texts]\n","    publications = list(filter(lambda p: len(p) > 0, publications))\n","    return publications\n","\n","# Extrai as sentenças do texto usando o SpaCy\n","def get_sentences(text: str):\n","    sentences = [sent.text.strip() for sent in NLP(text).sents]\n","    sentences = list(filter(lambda s: len(s) > 0, sentences))\n","    return sentences"],"metadata":{"id":"VMzk5tkh1jeK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HiddenPrints:\n","    def __enter__(self):\n","        self._original_stdout = sys.stdout\n","        sys.stdout = open(os.devnull, 'w')\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        sys.stdout.close()\n","        sys.stdout = self._original_stdout"],"metadata":{"id":"WakmJTNa7toD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove acentos e passa para lowercase\n","formatar = lambda palavra: unidecode(str(palavra).lower())\n","\n","STEMMER = SnowballStemmer(\"portuguese\", ignore_stopwords=True)\n","STOPWORDS = stopwords.words('portuguese')\n","\n","def extract_stem_tokens(sentence: str):\n","    tokens = [formatar(t) for t in word_tokenize(sentence)]\n","    important_tokens = list(filter(lambda t: not t in STOPWORDS and t.isalpha(), tokens))\n","    stems = [STEMMER.stem(t) for t in important_tokens]\n","    return stems"],"metadata":{"id":"MWeurgyD8M67"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Salvando a base de dados a partir dos PDFs"],"metadata":{"id":"3-_Tpsc_E5Mh"}},{"cell_type":"code","source":["pdf_list = listdir_drive(\"/content/drive/Shareddrives/IA 2023 - Projeto 1 Grupo 3/Dados/PDFs\", ['pdf'])\n","random.shuffle(pdf_list)\n","\n","with open(\"/content/drive/Shareddrives/IA 2023 - Projeto 1 Grupo 3/Dados/dataset_full.csv\", 'w', newline='') as csv_file:\n","    csv_writer = csv.writer(csv_file)\n","    for pdf in tqdm(pdf_list[:100], desc=\"Extraindo publicações dos PDFs\", position=0, leave=True):\n","        with HiddenPrints():\n","            for publication in get_publications(extract_text(pdf)):\n","                for sentence in get_sentences(publication):\n","                    tokens = extract_stem_tokens(sentence)\n","                    # Verifica se há algum token para formar a frase\n","                    if tokens:\n","                        data = analise_edit.extract_data(sentence)\n","                        # Frase original, tokenizada, modalidade, tipo de publicação e festividade\n","                        csv_writer.writerow([sentence, \" \".join(tokens), data[\"modalidade\"], data[\"tipo_publicacao\"], data[\"festividade\"]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2nRhNOA4PIV","executionInfo":{"status":"ok","timestamp":1695003923883,"user_tz":180,"elapsed":1176022,"user":{"displayName":"Alexandre Rodolfo Moreira Pereira","userId":"07277421830792925681"}},"outputId":"95890d61-1bf0-4681-f64d-70bc0fa0bec0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Extraindo publicações dos PDFs: 100%|██████████| 100/100 [19:35<00:00, 11.76s/it]\n"]}]},{"cell_type":"code","source":["with open(\"/content/drive/Shareddrives/IA 2023 - Projeto 1 Grupo 3/Dados/dataset_full.csv\", 'r') as csv_file:\n","    csv_reader = csv.reader(csv_file)\n","    sentence_data = [row for row in tqdm(csv_reader, desc=\"Carregando dataset\", position=0, leave=True)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoEjX7gl6U0w","executionInfo":{"status":"ok","timestamp":1695003938268,"user_tz":180,"elapsed":3342,"user":{"displayName":"Alexandre Rodolfo Moreira Pereira","userId":"07277421830792925681"}},"outputId":"cea5f9fc-dbb8-4213-db3a-c90195106438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Carregando publicações: 498219it [00:03, 135741.22it/s]\n"]}]},{"cell_type":"code","source":["print(sentence_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"91AbEv7s-X0h","executionInfo":{"status":"ok","timestamp":1695004031906,"user_tz":180,"elapsed":913,"user":{"displayName":"Alexandre Rodolfo Moreira Pereira","userId":"07277421830792925681"}},"outputId":"a1cda032-5ce9-4183-d58a-24d0d7fa1c7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['GABINETE DO PREFEITO DECRETO', 'gabinet prefeit decret', 'N.A.', 'Decreto', 'False']\n"]}]}]}