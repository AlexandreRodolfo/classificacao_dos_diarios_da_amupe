{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["AGgXqqgFxPUs","o_co0XUCwkTM","fOjOthOa7xOm"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Importando bibliotecas necessárias"],"metadata":{"id":"AGgXqqgFxPUs"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"PC1Tur4zxP_9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695093293143,"user_tz":180,"elapsed":29854,"user":{"displayName":"Alexandre Rodolfo Moreira Pereira","userId":"07277421830792925681"}},"outputId":"6f403a9f-1699-4c0f-d932-4ad1ec450f6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["!pip install PyMuPDF\n","!pip install plac\n","\n","# Bibliotecas necessárias\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import spacy\n","from spacy.lang.pt import stop_words\n","import random\n","import json\n","import os\n","import re\n","from itertools import chain\n","import sys\n","from __future__ import unicode_literals, print_function\n","from pathlib import Path\n","from tqdm import tqdm\n","import pandas as pd\n","import fitz\n","import plac\n","import numpy as np\n","import pickle\n","import base64\n","import csv\n","\n","csv.field_size_limit(sys.maxsize)"],"metadata":{"id":"mFHeSL8nxpVi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e268d67d-8c5f-4025-fbc3-a5cea2049ff7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyMuPDF\n","  Downloading PyMuPDF-1.23.3-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyMuPDFb==1.23.3 (from PyMuPDF)\n","  Downloading PyMuPDFb-1.23.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n","Successfully installed PyMuPDF-1.23.3 PyMuPDFb-1.23.3\n","Collecting plac\n","  Downloading plac-1.3.5-py2.py3-none-any.whl (22 kB)\n","Installing collected packages: plac\n","Successfully installed plac-1.3.5\n"]}]},{"cell_type":"code","source":["!python -m spacy download pt_core_news_sm"],"metadata":{"id":"m4NyJwPd4RRI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.stem import *\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords"],"metadata":{"id":"PU0J6RGqwn8D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install unidecode\n","from unidecode import unidecode"],"metadata":{"id":"YLVaoSSVwvxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install gensim\n","from gensim.models import Word2Vec\n","from gensim.test.utils import common_texts"],"metadata":{"id":"yduzXVufJx8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Garbage Collector - use it like gc.collect()\n","import gc\n","\n","# Custom Callback To Include in Callbacks List At Training Time\n","class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        gc.collect()"],"metadata":{"id":"I3N5v0tgTFhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HiddenPrints:\n","    def __enter__(self):\n","        self._original_stdout = sys.stdout\n","        sys.stdout = open(os.devnull, 'w')\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        sys.stdout.close()\n","        sys.stdout = self._original_stdout"],"metadata":{"id":"4IXtJITj_neJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Partindo frases"],"metadata":{"id":"fCCbGHkp3tlv"}},{"cell_type":"code","source":["# Ajusta a formatação dos textos\n","def remove_formatting(text):\n","    text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n","    while text.find(\"  \") != -1:\n","        text = text.replace(\"  \", \" \")\n","    return text"],"metadata":{"id":"M723B8tmDBCp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NLP = spacy.load(\"pt_core_news_sm\", disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"])\n","NLP.enable_pipe(\"senter\")\n","\n","def get_sentences(text: str):\n","    sentences = [sent.text.strip() for sent in NLP(text).sents]\n","    sentences = list(filter(lambda s: len(s) > 0, sentences))\n","    return sentences"],"metadata":{"id":"nNThGFB33wXR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Stemming"],"metadata":{"id":"o_co0XUCwkTM"}},{"cell_type":"code","source":["# Remove acentos e passa para lowercase\n","formatar = lambda palavra: unidecode(str(palavra).lower())\n","\n","STEMMER = SnowballStemmer(\"portuguese\", ignore_stopwords=True)\n","STOPWORDS = stopwords.words('portuguese')\n","\n","def extract_stem_tokens(sentence: str):\n","    tokens = [formatar(t) for t in word_tokenize(sentence)]\n","    important_tokens = list(filter(lambda t: not t in STOPWORDS and t.isalpha(), tokens))\n","    stems = [STEMMER.stem(t) for t in important_tokens]\n","    return stems"],"metadata":{"id":"TD3jewXsw_F8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Word2Vec + TF-IDF"],"metadata":{"id":"EM-JQ_j_KkS4"}},{"cell_type":"code","source":["# Word2Vec\n","print(\"Carregando modelo Word2Vec...\")\n","WORD2VEC = Word2Vec.load(\"/content/drive/Shareddrives/IA 2023 - Projeto 1 Grupo 3/Modelos/word2vec.model\")\n","\n","# TF-IDF\n","tf_idf_weights = {}\n","with open(\"/content/drive/Shareddrives/IA 2023 - Projeto 1 Grupo 3/Modelos/tf_idf_weights.csv\", 'r') as csv_file:\n","    csv_reader = csv.reader(csv_file)\n","    for row in tqdm(csv_reader, desc=\"Carregando tokens TF-IDF\", position=0, leave=True):\n","        tf_idf_weights[row[0]] = float(row[1])"],"metadata":{"id":"Eejv0acRKmmH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vectorize_sentence(sentence: str):\n","    return vectorize_tokens(extract_stem_tokens(sentence))\n","\n","def vectorize_tokens(tokens: list):\n","    if not tokens:\n","        return np.zeros_like(WORD2VEC.wv[0])\n","    tokens = list(filter(lambda t: (t in WORD2VEC.wv) and (t in tf_idf_weights.keys()), tokens))\n","    #tfidf = np.sqrt([[tf_idf_weights[t]] for t in tokens])\n","    tfidf = np.array([[tf_idf_weights[t]] for t in tokens])\n","    tfidf = np.log(tfidf / np.min(tfidf)) + 1\n","    w2v = np.array([WORD2VEC.wv[t] for t in tokens])\n","    return np.sum((w2v * tfidf) / sum(tfidf), axis=0) if len(tokens) > 0 else np.zeros_like(WORD2VEC.wv[0])"],"metadata":{"id":"IMtCdzdBi6Zb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Base de dados"],"metadata":{"id":"x5CqUPyBxK7k"}},{"cell_type":"code","source":["with open(\"/content/drive/Shareddrives/IA 2023 - Projeto 1 Grupo 3/Dados/dataset_full.csv\", 'r') as csv_file:\n","    csv_reader = csv.reader(csv_file)\n","    sentence_data = [row for row in tqdm(csv_reader, desc=\"Carregando base de dados\", position=0, leave=True)]"],"metadata":{"id":"JfSaKE5Ex2FZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695079836107,"user_tz":180,"elapsed":6300,"user":{"displayName":"Alexandre Rodolfo Moreira Pereira","userId":"07277421830792925681"}},"outputId":"50428c67-63df-49c0-80a2-7d3dd3be3358"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Carregando base de dados: 498219it [00:06, 76227.92it/s]\n"]}]},{"cell_type":"code","source":["lista_modalidades = [\n","    'Pregão Presencial - Ata de Registro de Preços', 'Ata de Registro de Preço', 'Seleção Pública Simplificada', 'Aviso de Chamamento Público',\n","    'Dispensa de Licitação', 'Tomada de Preço', 'Ata de Registro de Preços', 'Chamada Pública', 'Pregão', 'Convite', 'Concorrência',\n","    'Credenciamento', 'Inexigibilidade', 'Pregão Presencial', 'Regime Diferenciado de Contratação', 'Pregão Eletrônico'\n","]\n","lista_tipo_publicacao = [\n","    'Convocação de Licitante', 'Resultado de Julgamento', 'Termo de Comodato', 'Emenda Parlamentar', 'Nomeação Conselho', 'Anulação de ato',\n","    'Publicação de resultado', 'Processo Administrativo', 'Extrato de ata de registro de preços', 'Requerimento', 'Instrução normativa',\n","    'Lei Aldir Blanc', 'Proposta de Lei', 'Sessão Solene', 'Extrato de Termos de Compromisso', 'Cooperação Técnica',\n","    'Autorização de movimentação bancária', 'Ata da Sessão Pública', 'Regimento', 'Convênio', 'Memorial Descritivo', 'Anexos', 'Resolução',\n","    'Aviso de Demolição - Suspensão', 'Aprovação da Programação Anual de Saúde', 'Cessão de Uso', 'Autorização de uso de imóvel', 'Notificação',\n","    'Extrato de ata', 'Leilão', 'Manifestação de interesse social', 'Licenciamento Ambiental', 'Rescisão Contratual', 'Programação financeira',\n","    'Homologação', 'Portaria', 'Convocação para participar de Conselho Municipal', 'Inexigibilidade', 'Aviso de Demolição', 'Termo Aditivo',\n","    'Ata de abertura de envelope', 'Processo de impeachment', 'Aviso de Licitação', 'Concessão de Patrocínio', 'Processo Administrativo Sanitário',\n","    'Nota Informativa', 'Processo Seletivo', 'Licitação Deserta', 'Errata', 'Extrato de Contrato', 'Lançamento de tributos', 'Edital de Proclamas',\n","    'Termo de ajuste de contas', 'Promoção de religião', 'Atestado publicação RGF', 'Desapropriação', 'Revogação', 'Decreto', 'Termo de Fomento',\n","    'Atos de Pessoal', 'Autorização de Aplicação e Resgate', 'Credenciamento', 'Sanção contratual', 'Carta de Advertência',\n","    'Reequilíbrio Econômico Financeiro', 'Termo de Colaboração', 'Certidão', 'Execução de Pagamento', 'Cancelamento ou adiantamento indeterminado',\n","    'Conferência Municipal', 'Parcelamento e Confissão de Débitos Previdenciários', 'Aviso de Advertência', 'Adesão a ata de registro de preços',\n","    'Concurso Público', 'Parecer em credenciamento', 'Ratificação de dispensa', 'Campeonato esportivo', 'Concurso cultural', 'Audiência Pública',\n","    'Eleições de membros', 'Julgamento de Contas', 'Ata de Reunião', 'Contencioso Administrativo Fiscal', 'Lei', 'Precatórios FUNDEF',\n","    'Promulgação de Lei', 'Protocolo de Intenções', 'Cronograma de datas para tramitação de Lei', 'Certidão de Regularização Fundiária',\n","    'Prorrogação de credenciamento', 'Notificação de recebimento de recursos'\n","]"],"metadata":{"id":"T4twXmzbaEic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_tem_modalidades = {\"x\": [], \"y\": []}\n","dataset_tem_publicacoes = {\"x\": [], \"y\": []}\n","dataset_tem_festividade = {\"x\": [], \"y\": []}\n","dataset_modalidades = {\"x\": [], \"y\": []}\n","dataset_publicacoes = {\"x\": [], \"y\": []}\n","\n","for x in tqdm(sentence_data):\n","    try:\n","        inp = vectorize_tokens(x[1].split())\n","    except:\n","        continue\n","\n","    if inp is None or np.isnan(np.min(inp)):\n","        continue\n","\n","    out_modalidades = np.array([1 if x[2] == m else 0 for m in lista_modalidades], dtype=np.float32)\n","    out_publicacoes = np.array([1 if x[3] == p else 0 for p in lista_tipo_publicacao], dtype=np.float32)\n","\n","    if np.max(out_modalidades) > 0:\n","        dataset_modalidades[\"x\"] += [inp]\n","        dataset_modalidades[\"y\"] += [out_modalidades]\n","\n","    if np.max(out_publicacoes) > 0:\n","        dataset_publicacoes[\"x\"] += [inp]\n","        dataset_publicacoes[\"y\"] += [out_publicacoes]\n","\n","    dataset_tem_modalidades[\"x\"] += [inp]\n","    dataset_tem_modalidades[\"y\"] += [np.array([np.max(out_modalidades)])]\n","\n","    dataset_tem_publicacoes[\"x\"] += [inp]\n","    dataset_tem_publicacoes[\"y\"] += [np.array([np.max(out_publicacoes)])]\n","\n","    dataset_tem_festividade[\"x\"] += [inp]\n","    dataset_tem_festividade[\"y\"] += [np.array([1 if x[4] == \"True\" else 0])]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XgDU3lEa9W8","executionInfo":{"status":"ok","timestamp":1695081531814,"user_tz":180,"elapsed":115982,"user":{"displayName":"Alexandre Rodolfo Moreira Pereira","userId":"07277421830792925681"}},"outputId":"cfdc93ef-0656-4241-8abc-c16fbaaca938"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 498219/498219 [01:55<00:00, 4317.77it/s]\n"]}]},{"cell_type":"code","source":["def dividir_treino_teste(dataset, divisao=0.7):\n","    dataset_x = dataset[\"x\"]\n","    dataset_y = dataset[\"y\"]\n","    amostras_treino = int(len(dataset_x) * divisao)\n","\n","    return {\n","        \"treino_x\": np.array(dataset_x[:amostras_treino]),\n","        \"treino_y\": np.array(dataset_y[:amostras_treino]),\n","        \"teste_x\": np.array(dataset_x[amostras_treino:]),\n","        \"teste_y\": np.array(dataset_y[amostras_treino:]),\n","        \"input\": dataset_x[0].shape,\n","        \"output\": dataset_y[0].shape[0]\n","    }"],"metadata":{"id":"ZmkFQQQg0cC_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_modalidades = dividir_treino_teste(dataset_modalidades)\n","dataset_publicacoes = dividir_treino_teste(dataset_publicacoes)\n","dataset_tem_modalidades = dividir_treino_teste(dataset_tem_modalidades)\n","dataset_tem_publicacoes = dividir_treino_teste(dataset_tem_publicacoes)\n","dataset_tem_festividade = dividir_treino_teste(dataset_tem_festividade)"],"metadata":{"id":"-bZWd_Gg1Lto"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Treinamento dos Modelos"],"metadata":{"id":"dFVW4Al06laU"}},{"cell_type":"code","source":["# Publicações\n","dataset = dataset_publicacoes\n","model = keras.Sequential([\n","    layers.Input(shape=dataset[\"input\"]),\n","    layers.Normalization(),\n","    layers.Dense(64, activation='gelu'),\n","    layers.Dense(128, activation='gelu'),\n","    layers.Dense(64, activation='gelu'),\n","    layers.Dense(dataset[\"output\"], activation='softmax')\n","])\n","model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"],"metadata":{"id":"-FiWESRD6ngV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modalidades\n","dataset = dataset_modalidades\n","model = keras.Sequential([\n","    layers.Input(shape=dataset[\"input\"]),\n","    layers.Normalization(),\n","    layers.Dense(16, activation='gelu'),\n","    layers.Dense(32, activation='gelu'),\n","    layers.Dense(16, activation='gelu'),\n","    layers.Dense(dataset[\"output\"], activation='softmax')\n","])\n","model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"],"metadata":{"id":"qG2BRR838FNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modalidades head\n","dataset = dataset_tem_publicacoes\n","model = keras.Sequential([\n","    layers.Input(shape=dataset[\"input\"]),\n","    layers.Normalization(),\n","    layers.Dense(32, activation='gelu'),\n","    layers.Dense(dataset[\"output\"], activation='sigmoid')\n","])\n","model.compile(optimizer=keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"],"metadata":{"id":"kJW7CDMIjrCE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Festividade head\n","dataset = dataset_tem_festividade\n","model = keras.Sequential([\n","    layers.Input(shape=dataset[\"input\"]),\n","    layers.Normalization(),\n","    layers.Dense(32, activation='gelu'),\n","    layers.Dense(dataset[\"output\"], activation='sigmoid')\n","])\n","model.compile(optimizer=keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"],"metadata":{"id":"NLNILNeekv3u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Publicações head\n","dataset = dataset_tem_publicacoes\n","model = keras.Sequential([\n","    layers.Input(shape=dataset[\"input\"]),\n","    layers.Normalization(),\n","    layers.Dense(32, activation='gelu'),\n","    layers.Dense(8, activation='gelu'),\n","    layers.Dense(4, activation='gelu'),\n","    layers.Dense(dataset[\"output\"], activation='sigmoid')\n","])\n","model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"],"metadata":{"id":"n63M05lOzi4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(100):\n","    history = model.fit(\n","        dataset[\"treino_x\"], dataset[\"treino_y\"],\n","        validation_data=(dataset[\"teste_x\"], dataset[\"teste_y\"]),\n","        epochs=1,\n","        batch_size=64,\n","        validation_steps=8\n","    )\n","    model.save(f\"/content/drive/Shareddrives/IA 2023 - Projeto 1 Grupo 3/Modelos/publicacoes_e{(i+1)}.keras\")"],"metadata":{"id":"hUI8n5uuYTMR"},"execution_count":null,"outputs":[]}]}